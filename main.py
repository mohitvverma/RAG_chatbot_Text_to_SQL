import sys
from time import perf_counter
from TypeSQL.logger import logging
from typing import Union

import streamlit as st

from TypeSQL.pipeline.generative_pipeline import SQL2TextPipeline
from TypeSQL.exception import TypeSQLException
from app import setup_ChatUI_sidebar
from TypeSQL.settings import obtain_configs
from TypeSQL.prompt import SQL_MSG, AI_MSG, SUFFIX_ERROR_V1, SUFFIX_ERROR_V2


def initialize_session_state() -> None:
    try:
        logging.info("Initializing session state inside the Main")
        st.session_state.setdefault('isSetup', True)
        st.session_state.setdefault('sql_history', [])
        st.session_state.setdefault('sql_history_schema_mode', [])
        st.session_state.setdefault('chat_history', [])
        st.session_state.setdefault('isHumanFeedback', False)
        st.session_state.setdefault('isSQLModelOnline', True)
        st.session_state.setdefault('isResponseModelOnline', True)
        st.session_state.setdefault('user_input', "")
        st.session_state.setdefault('user_input_schema_mode', "")
        if "messages" not in st.session_state:
            st.session_state.messages = [
                {"role": "SQL", "content": SQL_MSG},
                {"role": "assistant", "content": AI_MSG}
            ]
        if "messages_schema_mode" not in st.session_state:
            st.session_state.messages_schema_mode = [
                {"role": "SQL", "content": SQL_MSG}
            ]
        logging.info("Successfully initiated Session states")
    except Exception as e:
        logging.error(e)
        print('Error Successfully initiated Session states')
        raise TypeSQLException(e, sys)


class Application():
    """
    Start Chat UI in streamlit application
    """
    def __init__(self, client: SQL2TextPipeline):
        logging.info("Initializing Application Constructor components")
        self.client = client
        self.db = client._get_db()
        self.sql_query = st.session_state.messages[-1]["content"]   #assign as latest sql_query generated by sql llm
        self.previous_user_input = st.session_state['user_input']   #assign as question asked by user about database
        self.sql_query_schema_mode = st.session_state.messages_schema_mode[-1]["content"]
        self.previous_user_input_schema_mode = st.session_state['user_input_schema_mode']

    def start_chat(self) -> None:
        """start application in standard_mode"""
        try:
            logging.info("Starting Start Chat inside Application")
            self.print_chat_history(st.session_state.messages)
            self.obtain_latest_sql_history(st.session_state['sql_history'])
            self.obtain_latest_chat_history(st.session_state['chat_history'])
            self.user_input = st.chat_input("Provide me an overview of database.")

            # if statement when user submits an input
            if self.user_input:
                with st.chat_message("user"):
                    st.markdown(self.user_input)
                st.session_state.messages.append({"role": "user", "content": self.user_input})

                # if-else statement to implement query generation or obtain user feedback about query generated
                if not st.session_state['isHumanFeedback']:
                    st.session_state['user_input'] = self.user_input
                    isModelAvailable = self.generate_sql_response(mode="standard",
                                                                  input=self.user_input,
                                                                  task="gen")
                    isSQLModelOnline = self.verify_llm_status(isModelAvailable=isModelAvailable,
                                                              llm='isSQLModelOnline',
                                                              isHumanFeedback=True)
                    if not isSQLModelOnline:
                        return
                    elif not SQL2TextPipeline.check_dml_ops(self.sql_dict['result']):
                        for _ in range(2):
                            st.session_state['sql_history'].pop()
                        st.session_state['isHumanFeedback'] = False
                        st.warning("Write Operations are not allowed. Please ask a new question.", icon="‚ö†Ô∏è")
                else:
                    self.obtain_user_feedback()

        except Exception as e:
            logging.error(e)
            raise TypeSQLException(e, sys)

        finally:
            logging.info("Finished Start Chat inside Application")

    def start_chat_schema_mode(self, db_schema: str) -> None:
        """start application in schema_mode"""
        try:
            logging.info("Starting Start Chat schema mode inside Application")
            self.print_chat_history(st.session_state.messages_schema_mode)
            self.obtain_latest_sql_history(st.session_state['sql_history_schema_mode'])
            self.user_input = st.chat_input("Provide me an overview of database.")

            # if statement when user submits an input
            if self.user_input:
                with st.chat_message("user"):
                    st.markdown(self.user_input)
                st.session_state.messages_schema_mode.append({"role": "user", "content": self.user_input})

                if "regen" in self.user_input.lower():
                    isModelAvailable = self.generate_sql_response(mode="schema_mode",
                                                                  input=self.previous_user_input_schema_mode,
                                                                  task="regen",
                                                                  db_schema=db_schema)
                else:
                    st.session_state['user_input_schema_mode'] = self.user_input
                    isModelAvailable = self.generate_sql_response(mode="schema_mode",
                                                                  input=self.user_input,
                                                                  task="gen",
                                                                  db_schema=db_schema)
                self.verify_llm_status(isModelAvailable=isModelAvailable, llm='isSQLModelOnline')
                logging.info("Successfully initiated schema mode inside Application")

        except Exception as e:
            logging.error(e)
            raise TypeSQLException(e, sys)

    def obtain_user_feedback(self) -> None:
        """obtain user feedback about query generated and generate human response based on sql query"""
        def check_query_validity(sql_query: str) -> bool:
            """check query is executable and doesn't contain write operations"""
            if not SQL2TextPipeline.check_dml_ops(sql_query):
                for _ in range(2):
                    st.session_state['sql_history'].pop()
                st.session_state['isHumanFeedback'] = False
                st.warning("Write Operations are not allowed. Please ask a new question.", icon="‚ö†Ô∏è")
                return False
            SQL2TextPipeline.test_query(self.db, sql_query)
            return True

        # Instructions pipeline
        try:
            if "skip" in self.user_input.lower():
                with st.chat_message("SQL", avatar=":material/database:"):
                    st.markdown("Skipped query.")
                st.session_state.messages.append({"role": "SQL", "content": "Skipped query."})
                st.session_state['isHumanFeedback'] = False
                return
            elif "regen" in self.user_input.lower():
                isModelAvailable = self.generate_sql_response(mode="standard",
                                                              input=self.previous_user_input,
                                                              task="regen")
                self.verify_llm_status(isModelAvailable=isModelAvailable, llm='isSQLModelOnline', isHumanFeedback=True)
                return
            elif "yes" in self.user_input.lower() or "y" == self.user_input.lower():
                sql_query = self.sql_query
                isQueryValid = check_query_validity(sql_query)
                if not isQueryValid:
                    return
            else:  # assume changes are required as proceed with sql query by user
                sql_query = self.user_input
                isQueryValid = check_query_validity(sql_query)
                if not isQueryValid:
                    return
                st.session_state['sql_history'].pop()
                st.session_state['sql_history'].append(f"Assistant: {sql_query}")
                self.obtain_latest_sql_history(st.session_state['sql_history'])

            isModelAvailable = self.generate_human_response(sql_query)
            self.verify_llm_status(isModelAvailable=isModelAvailable, llm='isResponseModelOnline',
                                   isHumanFeedback=False)
        except Exception as e:
            logging.exception(e)
            raise TypeSQLException(e, sys)

    def generate_sql_response(self, mode: str, input: str, task: str, db_schema: Union[str, None] = None) -> bool:
        """Generate sql query based on user input"""
        if mode == "standard":
            sql_history = st.session_state['sql_history']
            messages_state = st.session_state.messages
        elif mode == "schema_mode":
            sql_history = st.session_state['sql_history_schema_mode']
            messages_state = st.session_state.messages_schema_mode

        sql_chain_configs = {
            "mode": mode,
            "input": input,
            "task": task,
            "db_schema": db_schema
        }
        try:
            sql_chain, sql_prompt_with_keys = self.client.create_sql_chain(mode=mode, task=task)
            with st.spinner('Generating SQL Query...'):
                start_1 = perf_counter()
                with st.chat_message("SQL", avatar=":material/database:"):
                    with st.empty():  # enable streaming with st.empty so that the container can be overwritten
                        sql_results = self.invoke_sql_chain(sql_chain, sql_chain_configs)
                end_1 = perf_counter()
            if task == "regen":
                for _ in range(2):
                    sql_history.pop()

            logging.debug(f"Prompt_SQL: {self.sql_dict['prompt']}") #(standard_mode)
           # logging.debug(f"Prompt_SQL: {sql_prompt_with_keys.format(**keys)}") #(schema_mode)(need to pass keys into arg)

            messages_state.append({"role": "SQL", "content": sql_results})
            sql_history.append(f"User: {input}")
            sql_history.append(f"Assistant: {sql_results}")
            logging.info(f"Question : {input}")
            logging.info(f"SQL Query : {sql_results}")
            logging.info(f"Inference time used for sql generation: {end_1 - start_1} seconds\n")
            return True
        except Exception as error:
            messages_state.pop()
            st.warning(f"LLM server is not available. **Error**: {error}", icon="‚ö†Ô∏è")
            logging.error(f"{str(error)}")

    def invoke_sql_chain(self, sql_chain, configs: dict) -> str:

        "invoke sql chain based on mode eg: standard/schema_mode"
        try:
            if configs['mode'] == "standard":
                if configs['task'] == "gen":
                    extra = self.sql_history
                elif configs['task'] == "regen":
                    extra = self.sql_query

                self.sql_dict = sql_chain.invoke({"query": configs['input'], "extra": extra})
                self.sql_dict = SQL2TextPipeline.change_query(self.sql_dict, self.db)
                return self.sql_dict['result']
            elif configs['mode'] == "schema_mode":
                if configs['task'] == "gen":
                    keys = {"input": configs['input'],
                            "history": self.sql_history,
                            "table_info": configs['db_schema']}
                elif configs['task'] == "regen":
                    keys = {"input": configs['input'],
                            "wrong_sql_query": self.sql_query_schema_mode,
                            "table_info": configs['db_schema']}
                sql_results = sql_chain.invoke(keys)
                return sql_results

        except Exception as e:
            logging.error(e)
            raise TypeSQLException(e, sys)

    def generate_human_response(self, sql_query: str) -> bool:
        """Generate human response based on sql query"""
        try:
            response_chain = self.client.create_response_chain()
            prompt_response = self.client._get_response_prompt()
            sql_results = self.db.run(sql_query)
            formatted_prompt_response = prompt_response.format(history=self.chat_history,
                                                               question=self.previous_user_input,
                                                               query=sql_query,
                                                               results=sql_results if sql_results != "" else "NONE")
            # logger.debug(f"Prompt_Response: {formatted_prompt_response}") #dev
            with st.spinner('Generating Response...'):
                start_2 = perf_counter()
                with st.chat_message("assistant"):
                    with st.empty():  # enable streaming with st.empty so that the container can be overwritten
                        self.human_response = response_chain.invoke(formatted_prompt_response)
                end_2 = perf_counter()

            st.session_state.messages.append({"role": "assistant", "content": self.human_response})
            st.session_state['chat_history'].append(f"User: {self.previous_user_input}")
            st.session_state['chat_history'].append(f"Assistant: {self.human_response}")
            logging.info(f"SQL Results : {sql_results}")
            logging.info(f"Human-Readable Response : {self.human_response}")
            logging.info(f"Inference time used for response generation: {end_2 - start_2} seconds\n")
            return True

        except Exception as error:
            st.session_state.messages.pop()
            st.warning(f"LLM server is not available. **Error**: {error}", icon="‚ö†Ô∏è")
            logging.error(f"{str(error)}")
            raise TypeSQLException(error, sys)

    def print_chat_history(self, state) -> None:
        """To print all chat history in streamlit session"""
        for message in state:
            avatar = None
            content = message["content"]
            if message == state[0]:
                avatar = ":material/database:"
            elif message["role"] == "SQL":
                avatar = ":material/database:"
                content = f"```  \n {content}  \n ```"
            with st.chat_message(message["role"], avatar=avatar):
                st.markdown(content)

    def obtain_latest_sql_history(self, state) -> None:
        """To obtain 5 latest sql_history in str format to be passed into prompt_sql"""
        self.sql_history = '\n'.join(state[-10:])

    def obtain_latest_chat_history(self, state) -> None:
        """To obtain 5 latest chat_history in str format to be passed into prompt_response"""
        self.chat_history = '\n'.join(state[-10:])

    def error_handling(self, error) -> None:
        """To handle exception if query is not runnable or user input is unexpected."""
        st.session_state.messages.pop()
        if not st.session_state['isResponseModelOnline'] or not st.session_state['isSQLModelOnline']:
            st.warning(f"LLM server is not available. **Error**: {error}", icon="‚ö†Ô∏è")
        elif "yes" in self.user_input.lower() or "y" == self.user_input.lower():
            st.warning(f"**SQL Query generated is not executable.**{SUFFIX_ERROR_V2}", icon="‚ö†Ô∏è")
            if self.db.dialect == 'sqlite':
                st.toast("Please ensure database filename is correct.", icon="üö®")
        else:
            st.warning(f"**Please ensure you typed in correct SQL query or instructions.**{SUFFIX_ERROR_V1}", icon="‚ö†Ô∏è")
            if self.db.dialect == 'sqlite':
                st.toast("Please ensure database filename is correct.", icon="üö®")

    def verify_llm_status(self, isModelAvailable: bool, llm: str, isHumanFeedback: Union[bool, None] = None) -> bool:
        """To verify whether llm is online/offline and change state of "isHumanFeedback" in the end"""
        if isModelAvailable:
            st.session_state[llm] = True
            if isHumanFeedback is not None:
                st.session_state['isHumanFeedback'] = isHumanFeedback
            return True
        else:
            st.session_state[llm] = False
            return False


def main() -> None:
    """
    Main function to start application.
    """
    try:
        initialize_session_state()
        print('1')
        model_configs, prompt_configs = obtain_configs()
        print('2')
        configs = setup_ChatUI_sidebar()
        client = SQL2TextPipeline()
        client.setup(st.session_state['isSetup'], configs, model_configs, prompt_configs)
        st.session_state['isSetup'] = False
    except Exception as error:
        logging.error(f"Setup Fail. Error: {error}")
        st.warning(f"**Error 2**: {error, TypeSQLException(error,sys)}", icon="‚ö†Ô∏è")
        return

    chat = Application(client)
    #start chat with standard mode or db_schema_mode
    if not configs['isdbSchemaMode']:
        chat.start_chat()
    else:
        chat.start_chat_schema_mode(db_schema=configs["db_schema"])


if __name__ == "__main__":
    #logging.info("Initiated main")
    main()
